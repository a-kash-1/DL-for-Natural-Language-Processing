{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-793f9642db34>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\akash.sharma\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\akash.sharma\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\akash.sharma\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\akash.sharma\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\akash.sharma\\appdata\\local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "'''MNIST image recognition using Regression '''\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = mnist.train.images[0].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e1ce6c8b00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.gray()\n",
    "plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the hyperparameters and common parameters\n",
    "\n",
    "#Parametrs\n",
    "learning_rate = 0.01\n",
    "num_steps = 100\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "#Network Prameters\n",
    "n_hidden_1 = 300  #no. of neurons in layer 1\n",
    "n_hidden_2 = 300  # no. of neurons in layer 2\n",
    "num_input = 784   # = 28x28\n",
    "num_classes = 10  # = 0-9 \n",
    "\n",
    "#Training Parameters\n",
    "checkpoint_every = 100\n",
    "checkpoint_dir = './runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \n",
    "    #Assingning names to placeholders for later use\n",
    "    X = tf.placeholder(\"float\", [None, num_input], name = \"input_x\")\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes], name = \"input_y\")\n",
    "    \n",
    "    #Defining weights and biases and initializing them randomly\n",
    "    weights = {'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "              'h2' : tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "              'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))}\n",
    "    \n",
    "    biases = {'b1' : tf.random_normal([n_hidden_1]),\n",
    "             'b2': tf.random_normal([n_hidden_2]),\n",
    "             'out': tf.random_normal([num_classes])}\n",
    "    \n",
    "    #Defining the logistic regression operation which is basically weights X input + bias\n",
    "    #Or defining layers, in other words\n",
    "    layer_1 = tf.add(tf.matmul(X,weights['h1']), biases['b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']), biases['b2'])\n",
    "    logits = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "    \n",
    "    #converting the logits values into probabilities using Softmax\n",
    "    prediction = tf.nn.softmax(logits, name ='prediction')\n",
    "    \n",
    "    #Defining cost and Optimization\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    \n",
    "    #In the end making prediction \n",
    "    correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    #return correct_pred, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct_pred, accuracy = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "Modl = Model()\n",
    "X = Modl.X\n",
    "Y = Modl.Y\n",
    "\n",
    "checkpoint_dir = os.path.abspath(os.path.join(checkpoint_dir,\"checkpoints\"))\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"model\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "#Keeping the last 2 checkpoints to manage storage\n",
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 2601.7729, Training Accuracy= 0.125\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 2, Minibatch Loss= 2368.5613, Training Accuracy= 0.266\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 3, Minibatch Loss= 2132.1995, Training Accuracy= 0.305\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 4, Minibatch Loss= 1012.8754, Training Accuracy= 0.445\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 5, Minibatch Loss= 843.4351, Training Accuracy= 0.625\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 6, Minibatch Loss= 798.9785, Training Accuracy= 0.656\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 7, Minibatch Loss= 996.4614, Training Accuracy= 0.594\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 8, Minibatch Loss= 810.1909, Training Accuracy= 0.625\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 9, Minibatch Loss= 603.4980, Training Accuracy= 0.719\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 10, Minibatch Loss= 691.6633, Training Accuracy= 0.711\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 11, Minibatch Loss= 343.5082, Training Accuracy= 0.773\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 12, Minibatch Loss= 644.4461, Training Accuracy= 0.680\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 13, Minibatch Loss= 279.2101, Training Accuracy= 0.797\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 14, Minibatch Loss= 497.8379, Training Accuracy= 0.789\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 15, Minibatch Loss= 463.3292, Training Accuracy= 0.805\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 16, Minibatch Loss= 382.6861, Training Accuracy= 0.805\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 17, Minibatch Loss= 282.2623, Training Accuracy= 0.852\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 18, Minibatch Loss= 602.1234, Training Accuracy= 0.781\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 19, Minibatch Loss= 606.7737, Training Accuracy= 0.789\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 20, Minibatch Loss= 335.0984, Training Accuracy= 0.797\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 21, Minibatch Loss= 697.0371, Training Accuracy= 0.727\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 22, Minibatch Loss= 441.9795, Training Accuracy= 0.789\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 23, Minibatch Loss= 237.9103, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 24, Minibatch Loss= 390.6133, Training Accuracy= 0.867\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 25, Minibatch Loss= 360.9635, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 26, Minibatch Loss= 678.5505, Training Accuracy= 0.703\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 27, Minibatch Loss= 548.0282, Training Accuracy= 0.812\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 28, Minibatch Loss= 265.5427, Training Accuracy= 0.875\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 29, Minibatch Loss= 478.5392, Training Accuracy= 0.867\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 30, Minibatch Loss= 465.7961, Training Accuracy= 0.766\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 31, Minibatch Loss= 159.1292, Training Accuracy= 0.938\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 32, Minibatch Loss= 371.1149, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 33, Minibatch Loss= 173.6837, Training Accuracy= 0.875\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 34, Minibatch Loss= 363.8215, Training Accuracy= 0.812\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 35, Minibatch Loss= 199.1331, Training Accuracy= 0.883\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 36, Minibatch Loss= 421.7084, Training Accuracy= 0.836\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 37, Minibatch Loss= 292.2681, Training Accuracy= 0.859\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 38, Minibatch Loss= 274.5422, Training Accuracy= 0.883\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 39, Minibatch Loss= 235.1723, Training Accuracy= 0.852\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 40, Minibatch Loss= 377.9552, Training Accuracy= 0.812\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 41, Minibatch Loss= 292.4355, Training Accuracy= 0.836\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 42, Minibatch Loss= 439.6752, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 43, Minibatch Loss= 197.7816, Training Accuracy= 0.867\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 44, Minibatch Loss= 378.9011, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 45, Minibatch Loss= 340.6702, Training Accuracy= 0.836\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 46, Minibatch Loss= 415.4178, Training Accuracy= 0.859\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 47, Minibatch Loss= 536.9248, Training Accuracy= 0.758\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 48, Minibatch Loss= 266.8358, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 49, Minibatch Loss= 368.2150, Training Accuracy= 0.859\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 50, Minibatch Loss= 290.6026, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 51, Minibatch Loss= 516.4677, Training Accuracy= 0.867\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 52, Minibatch Loss= 345.1733, Training Accuracy= 0.852\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 53, Minibatch Loss= 372.1762, Training Accuracy= 0.812\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 54, Minibatch Loss= 435.9804, Training Accuracy= 0.836\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 55, Minibatch Loss= 309.1281, Training Accuracy= 0.805\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 56, Minibatch Loss= 243.9551, Training Accuracy= 0.867\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 57, Minibatch Loss= 234.6309, Training Accuracy= 0.898\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 58, Minibatch Loss= 231.1167, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 59, Minibatch Loss= 286.2249, Training Accuracy= 0.883\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 60, Minibatch Loss= 189.8566, Training Accuracy= 0.859\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 61, Minibatch Loss= 378.3393, Training Accuracy= 0.805\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 62, Minibatch Loss= 284.2830, Training Accuracy= 0.852\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 63, Minibatch Loss= 354.6563, Training Accuracy= 0.844\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 64, Minibatch Loss= 230.8770, Training Accuracy= 0.898\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 65, Minibatch Loss= 198.3643, Training Accuracy= 0.875\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 66, Minibatch Loss= 191.5007, Training Accuracy= 0.891\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 67, Minibatch Loss= 255.4235, Training Accuracy= 0.844\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 68, Minibatch Loss= 225.6265, Training Accuracy= 0.875\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 69, Minibatch Loss= 189.6665, Training Accuracy= 0.898\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 70, Minibatch Loss= 277.6903, Training Accuracy= 0.875\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 71, Minibatch Loss= 309.9023, Training Accuracy= 0.867\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 72, Minibatch Loss= 274.7955, Training Accuracy= 0.844\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 73, Minibatch Loss= 104.1680, Training Accuracy= 0.945\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 74, Minibatch Loss= 245.1315, Training Accuracy= 0.859\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 75, Minibatch Loss= 314.0181, Training Accuracy= 0.859\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 76, Minibatch Loss= 229.2228, Training Accuracy= 0.836\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 77, Minibatch Loss= 226.2806, Training Accuracy= 0.844\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 78, Minibatch Loss= 183.8920, Training Accuracy= 0.875\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 79, Minibatch Loss= 283.8384, Training Accuracy= 0.883\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 80, Minibatch Loss= 220.8069, Training Accuracy= 0.898\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 81, Minibatch Loss= 254.6327, Training Accuracy= 0.820\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 82, Minibatch Loss= 323.0535, Training Accuracy= 0.805\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 83, Minibatch Loss= 242.9576, Training Accuracy= 0.875\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 84, Minibatch Loss= 488.8366, Training Accuracy= 0.812\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 85, Minibatch Loss= 181.4976, Training Accuracy= 0.891\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 86, Minibatch Loss= 372.0328, Training Accuracy= 0.844\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 87, Minibatch Loss= 277.9287, Training Accuracy= 0.883\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 88, Minibatch Loss= 335.7555, Training Accuracy= 0.758\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 89, Minibatch Loss= 247.7182, Training Accuracy= 0.875\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 90, Minibatch Loss= 298.5189, Training Accuracy= 0.852\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 91, Minibatch Loss= 271.0602, Training Accuracy= 0.883\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 92, Minibatch Loss= 146.7784, Training Accuracy= 0.867\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 93, Minibatch Loss= 232.1101, Training Accuracy= 0.844\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 94, Minibatch Loss= 251.2847, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 95, Minibatch Loss= 232.1233, Training Accuracy= 0.844\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 96, Minibatch Loss= 315.9807, Training Accuracy= 0.797\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 97, Minibatch Loss= 213.6797, Training Accuracy= 0.828\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 98, Minibatch Loss= 308.5649, Training Accuracy= 0.844\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 99, Minibatch Loss= 209.6728, Training Accuracy= 0.891\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Step 100, Minibatch Loss= 296.9805, Training Accuracy= 0.844\n",
      "Saved Model checkpoint to C:\\Users\\akash.sharma\\Desktop\\runs\\checkpoints\\checkpoints\n",
      "\n",
      "Optimization finished!\n",
      "\n",
      "Testing Accuracy: 0.8569\n"
     ]
    }
   ],
   "source": [
    "#Begin training\n",
    "\n",
    "#Initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "all_loss = []\n",
    "\n",
    "#training starts\n",
    "with tf.Session() as sess:\n",
    "    writer_1 = tf.summary.FileWriter(\"./runs/summary/\",sess.graph)\n",
    "    \n",
    "    sum_var = tf.summary.scalar(\"loss\", Modl.accuracy)\n",
    "    write_op = tf.summary.merge_all()\n",
    "    \n",
    "    #Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1, num_steps+1):\n",
    "        #Extracting\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        #optimization\n",
    "        sess.run(Modl.train_op, feed_dict = {X: batch_x, Y: batch_y})\n",
    "        if step %display_step == 0:\n",
    "            #batch loss and accuracy\n",
    "            loss, acc = sess.run([Modl.loss, Modl.accuracy], feed_dict = {X: batch_x, Y: batch_y})\n",
    "            all_loss.append(loss)\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \"{:.3f}\".format(acc))\n",
    "            #writer_1.add_summary(summary, step)\n",
    "            print(\"Saved Model checkpoint to {}\\n\".format(checkpoint_dir))\n",
    "            \n",
    "        if step % checkpoint_every == 0:\n",
    "            path = saver.save(sess, checkpoint_prefix, global_step=step)\n",
    "            \n",
    "    print(\"Optimization finished!\\n\")\n",
    "    print(\"Testing Accuracy:\", sess.run(Modl.accuracy, feed_dict={X: mnist.test.images,Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference\n",
    "\n",
    "#Pointing the model checkpoint\n",
    "checkpoint_file = tf.train.latest_checkpoint(os.path.join(checkpoint_dir,'checkpoint'))\n",
    "print(checkpoint_file)\n",
    "print(os.path.join(checkpoint_dir,'checkpoint'))\n",
    "print(\"{}.meta\".format(os.path.join(checkpoint_dir,'checkpoint')))\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "\n",
    "#Load the input variable from the model\n",
    "input_x = tf.get_default_graph().get_operation_by_name(\"input_x\").outputs[0]\n",
    "\n",
    "#Load prediction Operation\n",
    "prediction = tf.get_default_graph().get_operation_by_name(\"prediction\").outputs[0]\n",
    "\n",
    "#Load test data\n",
    "test_data = np.array([mnist.test.images[0]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Restore the model from the checkpoint\n",
    "    saver.restore(sess, checkpoint_file)\n",
    "    #Execute the model to make predictions\n",
    "    data = sess.run(prediction, feed_dict ={input_x: test_data})\n",
    "    print(\"Predicted digit: \", data.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
